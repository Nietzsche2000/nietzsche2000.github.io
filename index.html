<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8" />
  <title>Monishwaran Maheswaran</title>
  <meta name="author" content="Monishwaran Maheswaran" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <link rel="icon" href="images/img_monish.png" type="image/png" />
  <link rel="stylesheet" href="stylesheet.css" />
</head>

<body>
  <div class="container">
    <header class="site-header" role="banner">
      <div>
        <p class="name">Monishwaran Maheswaran</p>

        <p>
          I'm an MS student in Electrical Engineering &amp; Computer Sciences at UC&nbsp;Berkeley
          where I am advised by Kurt Keutzer. I previously completed my undergraduate studies in EECS and
          in Mathematics at UC&nbsp;Berkeley. My interests span efficient and
          large-scale ML systems, optimization, and NLP.
        </p>

        <nav class="links" aria-label="Profile links">
          <a href="mailto:monishwaran@berkeley.edu">Email</a>
          <!-- <a href="https://www.monishwaran.com">Website</a> -->
          <a href="https://www.linkedin.com/in/monishwaran-maheswaran-m">LinkedIn</a>
          <a href="https://github.com/Nietzsche2000">GitHub</a>
          <a href="data/MonishwaranMaheswaran-CV.pdf">CV</a>
        </nav>
      </div>

      <figure class="avatar-wrap">
        <a href="images/img_monish.png">
          <img src="images/img_monish.png" alt="Portrait of Monishwaran Maheswaran" class="avatar" loading="lazy" />
        </a>
      </figure>
    </header>

    <main id="content">
      <!-- Education -->
      <section aria-labelledby="edu-heading">
        <h2 id="edu-heading">Education</h2>
        <ul>
          <li>
            <strong>UC Berkeley</strong> ‚Äî M.S. EECS, GPA 4.0/4.0; Advisor: Kurt Keutzer
          </li>
          <li>
            <strong>UC Berkeley</strong> ‚Äî Honors B.S. EECS; Honors B.A. Mathematics;
            Phi Beta Kappa
          </li>
          <!-- <li>
            <strong>Harvard University</strong> ‚Äî Secondary School Program, PHYSICS&nbsp;123
          </li> -->
        </ul>
      </section>

      <!-- Research Interests -->
      <section aria-labelledby="ri-heading">
        <h2 id="ri-heading">Research Interests</h2>
        <p>
          Efficient Machine Learning; Large-scale ML Systems; Optimization Models; Natural Language Processing.
        </p>
      </section>

      <!-- Publications -->
      <section aria-labelledby="pubs-heading">
        <h2 id="pubs-heading">Publications</h2>

        <div class="publist">
          <!-- RCD -->
          <article class="pub">
            <div class="pub-thumb">
              <img src="images/rcd_fig.png" alt="RCD paper thumbnail" loading="lazy" width="160"
                height="120" />
            </div>
            <div>
              <span class="papertitle">Residual Context Diffusion: Unleashing the Potential of Diffusion LLMs via Residual Denoising</span><br />
              <span class="authors">
                Yuezhou Hu*, Harman Singh*, <strong class="you">Monishwaran Maheswaran*</strong>,
                Haocheng Xi, Coleman Hooper, Jintao Zhang, Aditya Tomar,
                Michael W. Mahoney, Sewon Min, Mehrdad Farajtabar, Kurt Keutzer, Amir Gholami‚Ä†, Chenfeng Xu‚Ä†
              </span><br />
              <span class="meta"><strong>Preprint 2026</strong></span><br />
              <span class="pub-actions">
                <a href="https://yuezhouhu.github.io/projects/residual-context-diffusion/index.html">project page</a>
                <a href="https://arxiv.org/abs/2601.22954">arXiv</a>
                <a href="https://github.com/yuezhouhu/residual-context-diffusion">code</a>
                <a href="https://huggingface.co/collections/yuezhouhu/residual-context-diffusion">models</a>
              </span>
            </div>
          </article>
          <!-- Arbitrage -->
          <article class="pub">
            <div class="pub-thumb">
              <img src="images/arbitrage_flow.png" alt="Arbitrage paper thumbnail" loading="lazy" width="160"
                height="120" />
            </div>
            <div>
              <span class="papertitle">Arbitrage: Efficient Reasoning via Advantage-Aware Speculation</span><br />
              <span class="authors">
                <strong class="you">Monishwaran Maheswaran*</strong>, Rishabh Tiwari*, Yuezhou Hu*, Kerem Dilmen,
                Coleman Hooper, Haocheng Xi, Nicholas Lee, Mehrdad Farajtabar, Michael W. Mahoney, Kurt Keutzer, Amir
                Gholami
              </span><br />
              <span class="meta"><strong>Preprint 2025</strong></span><br />
              <span class="pub-actions">
                <a href="arbitrage.html">project page</a>
                <a href="https://arxiv.org/abs/2512.05033">arXiv</a>
                <a href="https://github.com/SqueezeAILab/Arbitrage">code</a>
              </span>
            </div>
          </article>
          <!-- TASER -->
          <article class="pub">
            <div class="pub-thumb">
              <img src="images/taser_paper.png" alt="TASER paper thumbnail" loading="lazy" width="160" height="120" />
            </div>
            <div>
              <span class="papertitle">TASER: Translation Assessment via Systematic Evaluation and
                Reasoning</span><br />
              <span class="authors">
                <strong class="you">Monishwaran Maheswaran</strong>, Marco Carini, Christian Federmann, Tony Diaz
              </span><br />
              <span class="meta"><strong>WMT @ EMNLP 2025</strong> (Apple internship work) ‚Ä¢ üèÜ <a
                  href="https://www2.statmt.org/wmt25/pdf/2025.wmt-1.23.pdf">Winner of WMT 2025
                  Shared Metrics Task (SoTA 2025)</a></span><br />
              <span class="pub-actions">
                <a href="https://arxiv.org/abs/2510.00255">arXiv</a>
                <a href="https://machinelearning.apple.com/research/taser">Apple MLR</a>
              </span>
            </div>
          </article>

          <!-- ETS -->
          <article class="pub">
            <div class="pub-thumb">
              <img src="images/ets_paper.png" alt="ETS paper thumbnail" loading="lazy" width="160" height="120" />
            </div>
            <div>
              <span class="papertitle">ETS: Efficient Tree Search for Inference-Time Scaling</span><br />
              <span class="authors">
                Coleman Hooper, Sehoon Kim, Suhong Moon, Kerem Dilmen, <strong class="you">Monishwaran
                  Maheswaran</strong>,
                Nicholas Lee, Michael W. Mahoney, Sophia Shao, Kurt Keutzer, Amir Gholami
              </span><br />
              <span class="meta"><strong>Preprint 2025</strong></span><br />
              <span class="pub-actions">
                <a href="https://arxiv.org/abs/2502.13575">arXiv</a>
              </span>
            </div>
          </article>

          <!-- Squeezed Attention -->
          <article class="pub">
            <div class="pub-thumb">
              <img src="images/squeezed_attention.png" alt="Squeezed Attention paper thumbnail" loading="lazy"
                width="160" height="120" />
            </div>
            <div>
              <span class="papertitle">Squeezed Attention: Accelerating Long-Context LLM Inference</span><br />
              <span class="authors">
                Coleman Hooper*, Sehoon Kim*, Hiva Mohammadzadeh, <strong class="you">Monishwaran Maheswaran</strong>,
                June Paik, Michael W. Mahoney, Kurt Keutzer, Amir Gholami
              </span><br />
              <span class="meta"><strong>Main Track @ ACL 2025</strong></span><br />
              <span class="pub-actions">
                <a href="https://arxiv.org/abs/2411.09688">arXiv</a>
                <a href="https://github.com/SqueezeAILab/SqueezedAttention">code</a>
              </span>
            </div>
          </article>

          <!-- 2017 Math -->
          <article class="pub">
            <div class="pub-thumb">
              <img src="images/math_harvard.jpg" alt="Summation Identities paper thumbnail" loading="lazy" width="160"
                height="120" />
            </div>
            <div>
              <span class="papertitle">Summation Identities</span><br />
              <span class="authors"><strong class="you">Monishwaran Maheswaran</strong>, Oliver Knill</span><br />
              <span class="meta"><strong>Harvard University Mathematics Department, 2017</strong></span><br />
              <span class="pub-actions">
                <a href="https://people.math.harvard.edu/~knill/pedagogy/monishwaran/theorems.pdf">paper</a>
              </span>
            </div>
          </article>
        </div>
      </section>

      <!-- Undergraduate Thesis -->
      <section aria-labelledby="thesis-heading">
        <h2 id="thesis-heading">Undergraduate Thesis</h2>
        <p>
          <strong>Scaling Laws and Training Dynamics in Extremely Wide Neural Networks</strong> ‚Äî UC&nbsp;Berkeley.
          Empirical and theoretical analysis of loss landscapes, minima distribution, and weight evolution in wide
          networks.
          Supervisors: Prof. Federico Pasqualotto (Mathematics).
        </p>
      </section>

      <!-- Industry
      <section aria-labelledby="industry-heading">
        <h2 id="industry-heading">Industry</h2>
        <ul>
          <li>
            <strong>Apple ‚Äî SWE Operations: Localization &amp; Release Engineering (Spring‚ÄìSummer&nbsp;2025)</strong>:
            Fine-tuning, preference optimization, and RAG for MT (50% HTER improvement; 75% cost reduction).
            Productionized LLM-based QE models with 5‚Äì6% cost savings across software localization.
          </li>
          <li>
            <strong>BetterAge, Inc. ‚Äî ML Engineering Intern (Summer&nbsp;2024)</strong>:
            Built LangChain agents with RAG and hallucination-reduction critique loops; +30% response accuracy; +25%
            decision efficiency via persona-aware MCTS.
          </li>
        </ul>
      </section> -->

      <!-- Research Experience
      <section aria-labelledby="research-exp-heading">
        <h2 id="research-exp-heading">Research</h2>
        <ul>
          <li>
            <strong>BAIR (PALLAS Group)</strong>: Mozilla-sponsored multi-agent ‚Äúpersistent context window‚Äù framework
            ($180k);
            inference-time scaling (ETS); Squeezed Attention; RAG pipeline optimization; TTS models for edge
            (LLaMA/GPT-2 variants, TPUs/GPUs).
          </li>
          <li>
            <strong>LBNL (Kolomensky Group)</strong>: GNNs &amp; GPT-PINNs for particle-trajectory prediction;
            distributed ML on Perlmutter (NERSC) for CUORE/CUPID.
          </li>
          <li>
            <strong>UC Berkeley Mathematics</strong>: GPT-based PINNs for PDEs; studies of extremely wide networks;
            Tensor-Train algorithms (distributed).
          </li>
        </ul>
      </section> -->

      <!-- Awards -->
      <section aria-labelledby="awards-heading">
        <h2 id="awards-heading">Awards</h2>
        <ul>
          <li>2023 ‚Äî <strong>Phi Beta Kappa</strong><br />
            For academic excellence in a broad array of undergraduate courses in the liberal arts and sciences. Top
            1/10th of UC&nbsp;Berkeley graduates campus wide in terms of GPA.</li>
          <li>2022 ‚Äî <strong>Texas Instruments‚ÄìUC&nbsp;Berkeley Class Design Contest Award</strong><br />
            For efficient design of new high performance hardware systems for signal processing, custom manufactured and
            assembled for an ASIC project funded by EECS Department.</li>
          <li>2022 ‚Äî <strong>Tau Beta Pi National Engineering Honor Society</strong><br />
            For outstanding performance in Engineering. Top 1/8th of UC&nbsp;Berkeley College of Engineering in terms of
            GPA.</li>
          <li>2021 ‚Äî <strong>IEEE-Eta Kappa Nu National Electrical Engineering Honor Society (HKN)</strong><br />
            For outstanding performance in EECS. Top 1/4th of UC&nbsp;Berkeley EECS students in terms of GPA.</li>
          <li>2019 ‚Äî <strong>INK Fellowship</strong><br />
            INK identifies and nurtures 20 young achievers worldwide who are passionate to redefine the fields they are
            in.</li>
        </ul>
      </section>

      <!-- Skills
      <section aria-labelledby="skills-heading">
        <h2 id="skills-heading">Skills</h2>
        <p>
          <strong>Programming</strong>: Python, C, C++, Java, Rust, Go, OCaml, SQL<br />
          <strong>Frameworks</strong>: PyTorch, JAX, Flax, TensorNetwork, NumPy, scikit-learn, gRPC, OpenMP, Matplotlib,
          seaborn, LangChain, ChromaDB<br />
          <strong>Software/Hardware</strong>: Git, Linux, Docker, Tmux, GDB; Intel intrinsics, SIMD, RISC-V/x86 asm
        </p>
      </section> -->

      <!-- Talks -->
      <section aria-labelledby="talks-heading">
        <h2 id="talks-heading">Invited Talks &amp; Interviews</h2>
        <ul>
          <li>2024 ‚Äî <a href="https://cdao-spring.coriniumintelligence.com/agenda">CDAO | The West Coast Data &amp;
              Analytics Event (San Francisco)</a></li>
          <li>2024 ‚Äî <a href="https://ny-ai-finance.re-work.co/schedule">RE.WORK | AI in Finance Summit (New York)</a>
          </li>
          <li>2020 ‚Äî <a href="https://www.youtube.com/watch?v=wHLxP0xHaW8">Engineering-Mind Podcast: Making Machines
              Feel</a></li>
          <li>2019 ‚Äî <a href="https://gitex.app.swapcard.com/event/gitex-2019/planning/UGxhbm5pbmdfNzU5NzM=">GITEX:
              Technology, Humans, Evolution: What Is the Future of Humankind?</a></li>
          <li>2019 ‚Äî <a href="https://youtu.be/iG26L3evqxI">INK Keynote: Generating Expeditious Solutions for Pressing
              Problems</a></li>
          <li>2019 ‚Äî <a href="https://www.youtube.com/watch?v=EqxtJyPI8rE">Rise of AI Berlin: Deep Learning To Save
              Lives</a></li>
          <li>2019 ‚Äî <a href="https://youtu.be/gUI0_oWfTWY">TEDx SereneMeadows: Curbing Suicides Using Machines</a></li>
          <li>2019 ‚Äî <a href="https://youtu.be/Jili1aCTd0o">TEDx BMSCE: The Neural Connect</a></li>
          <li>2019 ‚Äî <a href="https://youtu.be/_GmY6qeDnWg">TEDx IIITA: Deep Learning and Healthcare</a></li>
          <li>2019 ‚Äî <a href="https://www.youtube.com/watch?v=oNjxirApkZM">TEDx LakhotaLake: Saving Lives Through AI</a>
          </li>
          <li>2019 ‚Äî <a href="https://open.spotify.com/episode/2Uo1CywXcbqhbcVijbSxLb?si=Zfs&amp;nd=1">Moin Zukunft! ‚Äî
              Der Podcast vom Du Unternehmer-Magazin</a></li>
          <li>2019 ‚Äî <a
              href="https://open.spotify.com/episode/2yMLrO2f7Po5uEYFJ1zP9L?si=3WBMVMOdT2OG47lmQ4i6eg&amp;nd=1">Platform
              Tech Podcast</a></li>
        </ul>
      </section>

      <!-- Beyond Research -->
      <section aria-labelledby="beyond-heading">
        <h2 id="beyond-heading">Beyond Research</h2>
        <ul>
          <li>Besides my academic work, I love to teach. I share my projects and knowledge through numerous international keynotes and TEDx talks.</li>
          <li>Out of pure interest, I spend time analyzing the works of Friedrich Nietzsche, Ludwig Wittgenstein, and Bertrand Russell.</li>
          <li>I love endurance sports: I run ultramarathons, surf in San Francisco, and used to row at the California Lightweight Rowing Club at UC&nbsp;Berkeley.</li>
        </ul>
      </section>
    </main>

    <footer>
      <small>
        ¬© <span id="year"></span> Monishwaran Maheswaran ‚Ä¢ Template adapted from
        <a href="https://github.com/jonbarron/website">Jon Barron</a>
      </small>
      <blockquote class="site-quote">
        ‚ÄúI know of no better life purpose than to perish attempting the great and impossible.‚Äù
        <br />
        ‚Äï Friedrich Nietzsche
      </blockquote>
    </footer>
  </div>

  <script>
    document.getElementById('year').textContent = new Date().getFullYear();
  </script>
</body>

</html>